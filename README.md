# pseudo-kwebsite

Goals:
- Chrome extension development
https://www.freecodecamp.org/news/building-chrome-extension/
https://developer.chrome.com/docs/extensions/mv3/devguide/

- API from exisiting Models
Here are a few existing models that are commonly used to detect obscene data on the internet:

    Yahoo's Open NSFW: This is an open-source deep learning model developed by Yahoo's moderation team. It uses a convolutional neural network (CNN) to classify images as safe or not safe for work (NSFW). It is primarily focused on identifying explicit or pornographic content in images.

    Google's Perspective API: Developed by Google's Jigsaw, Perspective API is an API that uses machine learning models to analyze and detect various types of toxic and offensive content, including obscenity, hate speech, and harassment. It provides a text-based moderation solution.

    Sightengine: Sightengine is an AI-based content moderation platform that offers various models to detect and filter inappropriate content. It utilizes computer vision algorithms to analyze images and video frames for explicit or offensive material.

    Clarifai: Clarifai is an AI platform that provides visual recognition models capable of detecting explicit or NSFW content in images and videos. It offers pre-trained models that can be integrated into applications for content moderation.

    Microsoft Content Moderator: Microsoft Content Moderator is a cloud-based service that combines machine learning models and human review to detect and filter out explicit, adult, or otherwise inappropriate content. It offers image moderation, text moderation, and video moderation capabilities.

These are just a few examples of the existing models and services available for detecting obscene data on the internet. Different platforms and companies may have their own proprietary models and solutions tailored for content moderation purposes.


- Integration of API with the extension
- Testing extension on this website
